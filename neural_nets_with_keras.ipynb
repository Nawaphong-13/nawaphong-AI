{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "neural_nets_with_keras.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nawaphong-13/nawaphong-AI/blob/master/neural_nets_with_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CG7CUlGjY_l",
        "colab_type": "text"
      },
      "source": [
        "# ปัญญาประดิษฐ์ (Artificial Intelligence: AI)\n",
        "**Presented by: Nawaphong Yoochum**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sYVMLRsjY_l",
        "colab_type": "text"
      },
      "source": [
        "![zax](https://miro.medium.com/max/800/0*Z6s4lFY9R6zxmS14.jpg \"zax\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0AdUEQSjY_m",
        "colab_type": "text"
      },
      "source": [
        "# AI เกิดจาก?\n",
        "**คำว่า ปัญญาประดิษฐ์ (Artificial Intelligence: AI) ถูกใช้ครั้งแรกเมื่อประมาณ ค.ศ.1956 โดย John McCarthy เพื่อจัดงานสัมนาเชิงปฎิบัติการสำหรับนักวิจัยที่สนใจในหัวข้อที่กี่ยวข้องกัน เช่น ทฤษฎีออโตมาตา โครงข่ายประสาทเทียม และการศึกษาเกี่ยวกับความชาญฉลาด**\n",
        "\n",
        "# AI คือ?\n",
        "**ความหมายของปัญญาประดิษฐ์มีการให้ความหมาย และคำจำกัดความไว้มากมาย แต่มักเกี่ยวข้องกับกระบวนการคิดและการให้เหตุผลโดยมีมนุษย์เป็นต้นแบบ ซึ่งแตกแขนงออกเป็นหลายสาขา เช่น**\n",
        "\n",
        "* **การประมวลผลภาษาธรรมชาติ (Natural Language Processing: NLP)** ซึ่งเกี่ยวข้องกับการสื่อสารด้วยภาษาที่มนุษย์ใช้งาน เช่น ข้อความ ตัวอักษร เสียงพูด โดยตัวอย่าง NLP ที่พบเจอด้ง่ายในปัจจุบัน เช่น Chatbot ต่าง ๆ ไม่ว่าจะเป็น Siri ของบริษัท Apple, Alexa ของบริษัท Amazon และ Google Assistant ของบริษัท Google เป็นต้น\n",
        "\n",
        "* **คอมพิวเตอร์วิทัศน์ (Computer Vision)** ซึ่งเทียบได้กับการสร้างตาให้กับเครื่องจักร ที่สามารถรับรู้สิ่งแวดล้อมต่าง ๆ จากภาพ เช่น การรู้จำใบหน้ามนุษย์ การจำแนกประเภทของสิ่งของในภาพ หรือการตรวจหาตำแหน่งสิ่งของที่ต้องการจากภาพ เป็นต้น\n",
        "\n",
        "* **หุ่นยนต์ (Robotics)** ซึ่งเกี่ยวกับการสร้างเครื่องกลที่สามารถในลักษณะเฉพาะต่าง ๆ ได้อย่างแม่นยำและชาญฉลาด คล้ายกับการสร้างร่างการให้กับระบบปัญญาประดิษฐ์\n",
        "\n",
        "* **ระบบผู้เชี่ยวชาญ (Expert System)** เป็นการจำลองผู้เชี่ยงชาญในงานด้านนั้น ๆ เป็นชุดโปรแกรมคอมพิวเตอร์เพื่อให้สามารถทำงานนั้น ๆ ได้แทนผู้เชี่ยวชาญ หรือช่วยประกอบการตัดสินใจ เช่น ระบบซื้อขายหุ้น ระบบวินิจฉัยโรค เป็นต้น\n",
        "\n",
        "# ML คือ?\n",
        "**การเรียนรู้ของเครื่อง (Machine Learning: ML) เป็นเครื่องมือหนึ่งของปัญญาประดิษฐ์ที่มุ่งเน้นในการใช้ตัวอย่างหรือประสบการณ์เพื่อการเรียนรู้ โดยมนุษย์มีส่วนร่วมเพียงการออกแบบระบบเท่านั้น หลังจากนั้นระบบจะสกัดสิ่งสำคัญจากตัวอย่างเหล่านี้เอง หลังจากการเรียนรู้เสร็จสิ้นด้วยตัวอย่างจำนวนหนึ่งอย่างเพียงพอ เครื่องหรือระบบที่เรียนรู้แล้วสามารถนำไปใช้ในการประมวลผลของตัวอย่างใหม่ที่ไม่เคยพบมาก่อนได้อย่างมีประสทธิภาพ**\n",
        "\n",
        "\n",
        "**Figure 1.: Jeff Heaton Recording a Video**\n",
        "![zax](https://top6sites.com/wp-content/uploads/2020/05/AI-vs-ML-vs-Deep-Learning.png \"zax\")\n",
        "**Figure 2.: เปรียบเทียบระหว่าง โปรแกรมมิ่ง กับ Machine Learning**\n",
        "![zax](https://miro.medium.com/max/526/1*ZEMaGdLFmXjb3LveJHOEzA.png \"zax\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0no0VPWjY_m",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning จะมีคำศัพท์วิชาการที่คุณต้องเข้าใจอยู่(ไม่)นิดหน่อย\n",
        "**Figure 3.: Work flow ของ Machine Learning แบบ Supervised**\n",
        "![zax](https://miro.medium.com/max/875/1*ErgLGNnn7OfI-_o7aicMdQ.png \"zax\")\n",
        "\n",
        "* **Training Set** : ชุดข้อมูลฝึก เป็นชุดข้อมูลสำหรับฝึกฝนโมเดล Machine Learning โดยจะฝึกให้ผลลัพธ์ออกมาเป็นไปตามชุดข้อมูลต้นฉบับ **“หากข้อมูลภายในชุดข้อมูลฝึกมีค่าผิดหรือค่าที่ไม่ถูกต้อง ผลลัพธ์ที่ออกมาก็จะผิด”** ยกตัวอย่างเช่น ข้อมูลคนไข้ (น้ำหนัก,ส่วนสูง,ความดัน), ข้อมูลคนที่ชื้อของผ่าน Lazada (เพศ,อายุ,อาชีพ,ความสนใจพิเศษ)\n",
        "* **Test Set** : ชุดข้อมูลเอาไว้ทดสอบ โดย Test Set ไม่ควรเอาไปใช้ร่วมกับ Training Set เพราะถ้าทำแบบนั้น มันคือการเอาเฉลยของข้อสอบมาให้อ่านแล้วจากนั้นจึงให้ทำข้อสอบก็จะเกิดในเรื่องของ Model Over fitting กับข้อมูลชุดนั้นๆด้วย \n",
        "* **Label,Non Label หรือ Class** : เป็นตัวบ่งบอกว่าข้อมูลที่ให้ฝึกเป็นอะไร โดยแบบ Label จะใช้กับ Machine Learinig แบบมีผู้ช่วยสอน **(Supervised)** และ Non Label ใช้กับแบบไม่มีผู้ช่วยสอน **(Unsupervised)** เช่น ข้อมูลของคนไข้โดยมี Label/Class บอกว่าคนไข้คนนี้ป่วยหรือไม่ , ข้อมูลคนที่ชื้อของผ่าน Lazada โดย Label/Class บอกว่าเขาชื้อของใช้หรือของกิน\n",
        "* **Feature** : ภายในชุดข้อมูลฝึก/ทดสอบจะมีลักษณะเด่นที่ปรากฏอยู่ภายในข้อมูล เช่น ข้อมูลคนไข้ที่ป่วยเป็นไข้หวัดใหญ่ โดยลักษณะสำคัญคือ ไข้ขึ้นสูงกว่า 35 องศา , คนที่ชื้อของผ่าน Lazada โดยเขาชื้อของใช้ โดยลักษณะสำคัญคือ ของชิ้นที่ชื้อกำลังลดราคา ซึ่งภายในข้อมูลก็จะมีข้อมูลที่ไม่สำคัญอยู่ด้วย เราจะต้องคัดออกไปจากข้อมูลของเรา เหลือไว้เฉพาะอันที่ส่งผลข้อมูลจริง ๆ เท่านั้น\n",
        "* **Machine Learning Algorithm / Machine Learning Model** : จะเป็นการนำชุดข้อมูลฝึกฝน (Training Set) ที่ข้างในมีการระบุ Class (Label or Non Label) **โดยจะต้องเลือกลักษณะเด่น (Feature) ของข้อมูลนั้นมาก่อนแล้ว** จากนั้นเอาข้อมูลเหล่านั้นมาคำนวณผ่านหลักคณิตศาสตร์และสถิติขึ้นอยู่โมเดลที่เราเลือกโดยขั้นตอนนี้เราเรียกว่าการฝึกฝนโมเดล (Train Model) โดยเมื่อฝึกฝนเสร็จเราก็จะโมเดลที่สามารถทำนาย Class/Label จาก input ออกมาได้\n",
        "* **Predict Model** : หลังจากได้ ML Model มาแล้ว นำเอาโมเดลไปใช้งานโดยการป้อน input ให้โมเดลนั้น ๆ แล้วตัวโมเดลจะให้คำตอบ (Class/Label) โดยอ้างอิงจาก Train Set ของเรา โดยเราหวังว่า ผลลัพธ์ที่ออกมาจะเป็นไปตามที่เราคาดหวังไว้\n",
        "* **Expected Label or Value** : หลังจากได้ Output ของการทำนาย โดยเราหวังว่ามันจะออกมาถูก โดยบางครั้งเราสามารถมองเห็นผลลัพธ์ด้วยตาเปล่า เช่น ทำนายว่าเลขนี้คือเลขอะไร เวลาที่ได้คำตอบจากโมเดล เราก็สามารถตรวจได้ด้วยตาเปล่าเลย แต่บางอย่างเราไม่สามารถทำการตรวจสอบผลลัพธ์ด้วยตาเปล่าหรือคำตอบนั้นมีจำนวนมาก ทำให้เราต้องมีการทดสอบขึ้นมา โดยเรียกว่า การประเมินโมเดล (E-Test/Evaluate) โดยเอา Output มาเทียบกับเฉลยที่เรามี หรือ Good global โดยค่าใช้ตรวจสอบก็มีหลากหลายเช่น ACC , F1Score , Confusion matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwh7469xjY_m",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning มีกี่ประเภท ?\n",
        "**จะมีอยู่ 2 แบบใหญ่ๆคือ**\n",
        "* แบบมีผู้ช่วยสอน (Supervised)\n",
        "* แบบไม่มีผู้ช่วยสอน (Unsupervised)\n",
        "\n",
        "**Figure 4.:Machine Learning Type**\n",
        "![zax](https://miro.medium.com/max/875/1*FOrwV4L_bTEeeUoUrAgSNg.png \"zax\")\n",
        "\n",
        "# แบบที่ 1 แบบมีผู้ช่วยสอน (Supervised)\n",
        "\n",
        "**Figure 5.:แบบ Supervised**\n",
        "![zax](https://miro.medium.com/max/875/1*sxI24EY_gvknBDYALp2yoA.png \"zax\")\n",
        "\n",
        "**โดยในแบบนี้ เราจะมีสิ่งที่เรียกว่า เฉลย (Label/Class) หน้าที่ของมันคือจำแนกประเภทของข้อมูลนั้นๆ (Category) หรือบ่งบอกถึงปริมาณก็ได้ โดยสามารถแบ่งออกมาได้อีก 2 ประเภทคือ**\n",
        "* Classification หรือ การจำแนกประเภท\n",
        "* Regression หรือ การวิเคราะห์การถดถอย\n",
        "\n",
        "# Classification หรือ การจำแนกประเภท\n",
        "**เป็นการจำแนกข้อมูลออกเป็นประเภทต่าง ๆ ตามที่ Label ได้กำหนดไว้ โดย Machine Learning ประเภท Classification จะให้คำตอบเป็น Label / Class เท่านั้น ไม่สามารถให้คำตอบที่นอกเหนือจาก Label ในชุดฝึกฝน หรือออกมาเป็นตัวเลขที่ผ่านการคำนวณได้นั้นเอง โดย ML Model สำหรับงาน Classification ที่เด่น ๆ ได้แก่ KNN, SVM, Logistic Regression, Decision Treec และ Neural Network เป็นต้น**\n",
        "\n",
        "# Regression หรือ การวิเคราะห์การถดถอย\n",
        "**คือการนำ input เข้าไปฝึกฝนและให้คำตอบออกมาเป็นตัวเลขเท่านั้น คำตอบไม่สามารถออกมาเป็น Label/Class ได้ โดย ML Model สำหรับงาน Regression ที่เด่น ๆ ได้แก่ Linear Regression, Ridge Regression, Lasso, Elastic Net, SGD**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFNeA122jY_n",
        "colab_type": "text"
      },
      "source": [
        "# แบบที่ 2 แบบไม่มีผู้ช่วยสอน (Unsupervised)\n",
        "\n",
        "**Figure 6.:จำแนกประเภทของข้อมูล โดยไม่ต้องมี Label data**\n",
        "![zax](https://miro.medium.com/max/434/1*5RDVF1xW0LfXjoxZp6jI1Q.png \"zax\")\n",
        "**Unsupervised จะต่างจาก Supervised โดยสิ้นเชิงโดยวิธีนี้จะเน้นไปที่การวิเคราะห์ข้อมูล (Analysist) มากกว่า เช่นการหา pattern ของข้อมูลเพื่อทำการจัดกลุ่มของของมูล (Clustering) หรือจะเป็นการลดมิติของข้อมูล (Dimension Reduction) เพื่อหา Feature ของข้อมูล**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeqXAbsXjY_n",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network คืออะไร?\n",
        "**โครงข่ายประสาทเทียม (Artificial Neural Network, ANNs) หรือเรียกสั้นๆว่า โครงข่ายประสาท (Neural Network, Neural Net, NN) คือโมเดลทางคณิตศาสตร์หรือโมเดลทางคอมพิวเตอร์สำหรับประมวลผลสารสนเทศด้วยการคำนวณแบบ คอนเนคชันนิสต์ (Connectionist) เพื่อจำลองการทำงานของเครือข่ายประสาทในสมองมนุษย์**\n",
        "**Figure 7.:เซลล์ประสาท**\n",
        "![zax](https://miro.medium.com/max/600/1*9HEzWvaSXPF1MTIxqYzTNg.jpeg \"zax\")\n",
        "\n",
        "**โดยแนวคิดเริ่มต้นของเทคนิคนี้ได้มากจากการศึกษาโครงข่ายประสาทไฟฟ้าทางชีวภาพ (Bioelectric Network) ในสมอง ซึ่งประกอบไปด้วย เซลล์ประสาทหรือนิวรอน (Neuron) และจุดประสานประสาท (Synapses) ซึ่งในแต่ละเซลล์จะประกอบไปด้วยปลายการรับกระแสประสาทเรียกว่า เดนไดรน์ (Dendrite) ซึ่งเป็น Input และปลายในการส่งกระแสประสาทเรียกว่า แอดซอน (Axon) ซึ่งเป็นเหมือน Output**\n",
        "\n",
        "# ส่วนประกอบของ Neural Network\n",
        "**Figure 8.:ส่วนประกอบของ Neural Network**\n",
        "![zax](https://miro.medium.com/max/729/1*CYR1Hge5ZrSieLAs9URpzg.jpeg \"zax\")\n",
        "\n",
        "* **Neurons (ก้อนกลมๆ)**\n",
        "ข้างใน Neuron จะต่างกันตาม layer ที่มันอยู่ โดยถ้าเป็น Input ข้างในตัวมันก็จะมีข้อมูลที่รับมา แต่ถ้าเป็น Hidden Layer ก็จะมีสมการที่ช่วยในการคำนวณเพื่อทำนายว่าเป็นคลาสอะไร หรือคำนวณแบบถดถอย (Regression) ก็ได้ แต่ถ้าเป็น Output ก็จะเป็นตัวที่บ่งบอกว่าเป็นคลาสอะไรนั้นเอง\n",
        "* **Input Layer (สีเขียว)**\n",
        "มีหน้าที่ในการรับข้อมูลเข้ามาในโครงข่ายประสาทโดย Input Layer จะเพียงชั้นเดียวเท่านั้นและมีหน้าที่ส่งข้อมูลไปยังชั้นถัดไป (Hidden Layer)\n",
        "* **Hidden Layer (สีส้ม)**\n",
        "มีหน้าที่รับข้อมูลจาก Layer ก่อนหน้า จะสังเกตุว่า Hidden Layer สามารถมีจำนวนมากกว่า 1 ได้ และโดยพื้นฐาน ถ้าเรายิ่งต้องการความแม่นยำที่มากขึ้นเราก็จะเพิ่มจำนวนชั้นของ Hidden Layer และจำนวน Neurons ให้มากขึ้นก็จะช่วยได้ (ไม่เสมอไป)\n",
        "* **Output Layer (สีฟ้า)**\n",
        "เป็น output layer ที่อยู่ท้ายสุดรอรับค่าจาก hidden layer อันสุดท้าย โดยในชั้น output นั้นแต่ละ neurons จะมีค่าน้ำหนักของคลาสอยู่เช่น เรามีประเภทของ output ทั้งหมดหมด 2 แบบคือ แมว กับ หมาเพราะฉนั้น output layer ของเราจะมี neurons 2 ตัว ตัวแรกอาจจะเป็นหมา neurons ตัวที่สองจะเป็นแมว โดยเมื่อข้อมูลผ่าน hidden layer ไปสู่ output ไปแล้ว neurons ทั้ง 2 ตัวจะมีค่าข้างในไม่เท่ากัน โดยที่** ***neuron ตัวไหนมีน้ำหนักมากกว่ากัน แสดงว่าเป็นคลาสนั้น***\n",
        "\n",
        "# และใน hidden layer มีอีกสองสิ่งที่ถูกซ่อนไว้คือ bias และ weight\n",
        "**Figure 8.:B1,B2 และ Wx**\n",
        "![zax](https://miro.medium.com/max/875/1*ZFRdep_Qq1q8_7RqZRL8Zg.png \"zax\")\n",
        "\n",
        "* โดยทุกๆ hidden layer จะมี **bias** เชื่อมต่ออยู่เพื่อให้ทุกๆการคำนวณเพื่อส่งต่อมีความเท่าเทียมกัน ตีความหมายง่ายๆคือ ทุกๆ neurons ใน hidden layer จะต้องมี **bias** เข้าไปคำนวณเพื่อให้ decision boundary ไม่จำเป็นต้องผ่านจุด origin\n",
        "* ส่วน **Weight** จะเป็นน้ำหนักซึ่งมันจะส่งผลทุกๆ neurons มีค่า output ที่ไม่เท่ากัน ทำให้แต่ละคลาสมีน้ำหนักไม่เท่ากันเวลาคำนวณว่าเป็นคลาสไหน ทำให้เราสามารถแยกว่าข้อมูลนี้เป็นคลาสอะไรได้ด้วยการดูตัวเลขที่ output\n",
        "\n",
        "# Perceptron\n",
        "**Figure 9.:https://www.oreilly.com/library/view/neural-networks-and/9781492037354/ch01.html**\n",
        "![zax](https://miro.medium.com/max/384/1*wKSR0n-QMKcky5akfJhUSw.png \"zax\")\n",
        "\n",
        "**โดย 1 neuron จะทำนายได้แค่ 1 คลาส (คล้ายกับ Logistic Regression) ถ้าอยากมี output หลายๆคลาสก็ต้องมีหลายๆ LTU นั้นเอง โดยในตัว Neuron จะมี Weight Sum คือการรวมน้ำหนักที่ต่อเข้า Neuron ด้วยสมการเฉพาะตัว และมี Step function ในการคำนวณค่าออกมาว่าเป็นคลาสอะไร**\n",
        "\n",
        "**Figure 10.:https://www.oreilly.com/library/view/neural-networks-and/9781492037354/ch01.html**\n",
        "![zax](https://miro.medium.com/max/875/1*sauVjqhmvJxwtQZojEqHFw.png \"zax\")\n",
        "\n",
        "# Multi-layer Perceptron\n",
        "**Figure 10.:Multi-layer Perceptron**\n",
        "![zax](https://miro.medium.com/max/875/1*6Y4rddcnu_jFIwHq_mAouQ.png \"zax\")\n",
        "\n",
        "# Backpropagation\n",
        "\n",
        "**หลังจากมีการเพิ่ม MLP เข้าไป Neural network ก็ตัน ๆ ไปจนกระทั่งถึงปี 1986 Rumelhart ได้ตีพิมพ์ paper อัลกอริทึมที่ชื่อว่า “Backpropagation”\n",
        "ปกติ Neural Network เราจะเรียกว่า Feed Forward / Forward pass คือการไปข้างหน้า หมายความว่าปกติแล้ว NN จะรับข้อมูลจาก Input Layer สร้างน้ำหนัก(W) แล้วประมวลผลผ่าน Hidden Layer แล้วออกที่ Output เลย แต่ทีนี้เราให้มันย้อนกลับจาก output กลับมาที่ input โดยที่ Backpropagation หน้าที่ของมันแปลเป็นไทยง่ายๆคือ**\n",
        "***ปรับค่าน้ำหนัก(W)ในแต่ละเส้นอีกครั้งโดยดูจาก error/cost ที่เกิดขึ้นในแต่ละ neurons***\n",
        "\n",
        "**Figure 11.:Backpropagation**\n",
        "![zax](https://miro.medium.com/max/875/1*dATwpOb7HF3asp18ddZQVg.png \"zax\")\n",
        "\n",
        "# Optimization Algorithms\n",
        "\n",
        "จากการมาถึงของ Backpropagation เราจะปรับน้ำหนักในแต่ละจุดให้ดีขึ้นเพื่อให้ได้ค่าที่แม่นยำมากยิ่งขึ้นกว่าเดิมแต่วิธีการหาค่าน้ำหนัก(W) ใหม่คือการใช้สิ่งที่เรียกว่า Optimization Algorithms แปลเป็นไทยได้ว่า “อัลกอริทึมการเพิ่มประสิทธิภาพ” ซึ่งทำหน้าที่ปรับปรุงค่าต่าง ๆ ใน neural network ทำให้ output เข้าใกล้เป้าหมายมากขึ้น\n",
        "**Figure 12.:Optimization Algorithms**\n",
        "![zax](https://miro.medium.com/max/419/1*CTIZsQR6AwCPcLpS9WPyzg.png \"zax\")\n",
        "\n",
        "# Activation Function\n",
        "\n",
        "**Figure 12.:Activation Function**\n",
        "![zax](https://miro.medium.com/max/750/1*fSdhPRjTiAXO13tooELWaw.png \"zax\")\n",
        "**เมื่อเราใช้ backpropagation แล้วเราก็ไม่สามารถใช้ step function ได้อีกต่อไปเราจึงเปลี่ยนมาใช้** ***Activation Function (ฟังก์ชั่นการกระตุ้น)*** **มาคำนวณหลังจากที่คำนวณ Weight ของ neuron เสร็จแล้วเพื่อหาว่าเป็นคลาสนี้หรือไม่โดยค่าที่ออกมาจะเป็นความน่าจะเป็นว่าใช่คลาสนั้นหรือไม่ และจะเป็นน้ำหนักให้กับ neurons ตัวถัดไป**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBKA_SFajY_o",
        "colab_type": "text"
      },
      "source": [
        "# Implementation Artificial Neural Network\n",
        "\n",
        "**Figure 13.:Implementation**\n",
        "![zax](https://twilio-cms-prod.s3.amazonaws.com/images/jupyter_python_numpy.width-808.png \"zax\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN3lZlLPjY_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"ann\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "\n",
        "# Ignore useless warnings (see SciPy issue #5998)\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RKvY-A0jY_r",
        "colab_type": "text"
      },
      "source": [
        "# Building an Image Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrZfMbtjjY_r",
        "colab_type": "text"
      },
      "source": [
        "First let's import TensorFlow and Keras.\n",
        "\n",
        "**Figure 14.:Tensorflow-Keras**\n",
        "![zax](https://miro.medium.com/max/1000/1*HLziSq4zU8TNCNJBuuQQVw.jpeg \"zax\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvBl3vWXjY_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4lDX7GojY_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hVCE6ibjY_v",
        "colab_type": "text"
      },
      "source": [
        "Let's start by loading the fashion MNIST dataset. Keras has a number of functions to load popular datasets in `keras.datasets`. The dataset is already split for you between a training set and a test set, but it can be useful to split the training set further to have a validation set:\n",
        "\n",
        "**Figure 15.:fashion MNIST dataset**\n",
        "![zax](https://miro.medium.com/max/798/1*PtQ2I-3RIFiCypor4u_Nbg.jpeg \"zax\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsqz1m_JjY_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oz8iRZBjY_y",
        "colab_type": "text"
      },
      "source": [
        "The training set contains 60,000 grayscale images, each 28x28 pixels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbdCnhxgjY_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_full.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v2eVL99jY_2",
        "colab_type": "text"
      },
      "source": [
        "Each pixel intensity is represented as a byte (0 to 255):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7RYU8_RjY_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_full.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFu6ZWbVjY_4",
        "colab_type": "text"
      },
      "source": [
        "Let's split the full training set into a validation set and a (smaller) training set. We also scale the pixel intensities down to the 0-1 range and convert them to floats, by dividing by 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K11hBP5ajY_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiKqOhYqjY_6",
        "colab_type": "text"
      },
      "source": [
        "You can plot an image using Matplotlib's `imshow()` function, with a `'binary'`\n",
        " color map:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z58L2Y6pjY_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(X_train[0], cmap=\"binary\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VnZlh_MjY_8",
        "colab_type": "text"
      },
      "source": [
        "The labels are the class IDs (represented as uint8), from 0 to 9:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkwRLPNcjY_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkXZ-97kjY__",
        "colab_type": "text"
      },
      "source": [
        "Here are the corresponding class names:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLGIZVgWjY__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdfEaoCzjZAB",
        "colab_type": "text"
      },
      "source": [
        "So the first image in the training set is a coat:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YlFHY-xjZAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names[y_train[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oam7p1qejZAD",
        "colab_type": "text"
      },
      "source": [
        "The validation set contains 5,000 images, and the test set contains 10,000 images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOmfwFxvjZAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_valid.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olsdZITEjZAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHsceQq6jZAI",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at a sample of the images in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_CpwiDpjZAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_rows = 4\n",
        "n_cols = 10\n",
        "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
        "        plt.axis('off')\n",
        "        plt.title(class_names[y_train[index]], fontsize=12)\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "save_fig('fashion_mnist_plot', tight_layout=False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToY82py7jZAK",
        "colab_type": "text"
      },
      "source": [
        "## Creating the model using the Sequential API "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKalVpj-jZAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jf2TU2YjZAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA7J8SL5jZAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUCV4IAYjZAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"relu\", name=\"Layer_Dense\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoigKcdfjZAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFXkPvDujZAS",
        "colab_type": "text"
      },
      "source": [
        "You can easily get a model’s list of layers, to fetch a layer by its index, or you can fetch it by name:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDTE3tRejZAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odsQ6zq8jZAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwJ1eaKojZAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden1 = model.layers[1]\n",
        "hidden1.name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjAAjAihjZAY",
        "colab_type": "text"
      },
      "source": [
        "All the parameters of a layer can be accessed using its `get_weights()` and `set_weights()` methods. For a Dense layer, this includes both the connection weights and the bias terms:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EgwSRPLjZAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights, biases = hidden1.get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u1oK3fojZAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS0VNtZgjZAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cNNVDzIjZAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "biases"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td76dtm1jZAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "biases.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwxAavkOjZAg",
        "colab_type": "text"
      },
      "source": [
        "## Compiling the model\n",
        "After a model is created, you must call its `compile()` method to specify the loss function and the optimizer to use. Optionally, you can specify a list of extra metrics to compute during training and evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9IbWSVmjZAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxiyJPbvjZAi",
        "colab_type": "text"
      },
      "source": [
        "## Training and evaluating the model \n",
        "Now the model is ready to be trained. For this we simply need to call its `fit()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YqNorqvqjZAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXPlxOg9jZAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history.params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyPd_O6OjZAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(history.epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9KLxHuwjZAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history.history.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ior3RYFhjZAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "save_fig(\"keras_learning_curves_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-lF69OHjZAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R5-xWFBjZAr",
        "colab_type": "text"
      },
      "source": [
        "## Using the model to make predictions \n",
        "Next, we can use the model’s `predict()` method to make predictions on new instances. Since we don’t have actual new instances, we will just use the first three instances of the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC2QxJ3ajZAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_new = X_test[:3]\n",
        "y_proba = model.predict(X_new)\n",
        "y_proba.round(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k73aW1AjZAt",
        "colab_type": "text"
      },
      "source": [
        "If you only care about the class with the highest estimated probability (even if that probability is quite low), then you can use the `predict_classes()` method instead:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmPjZ5p7jZAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict_classes(X_new)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxuayfRtjZAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_new = np.argmax(model.predict(X_new), axis=-1)\n",
        "y_pred_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT-sv-uPjZAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.array(class_names)[y_pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOZH1916jZA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(7.2, 2.4))\n",
        "for index, image in enumerate(X_new):\n",
        "    plt.subplot(1, 3, index + 1)\n",
        "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
        "    plt.axis('off')\n",
        "    plt.title(class_names[y_test[index]], fontsize=12)\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "save_fig('fashion_mnist_images_plot', tight_layout=False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZaLEk4njZA4",
        "colab_type": "text"
      },
      "source": [
        "# Saving and Restoring a Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K33JaTvjZA4",
        "colab_type": "text"
      },
      "source": [
        "When using the Sequential API or the Functional API, saving a trained Keras model is as simple as it gets:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99ZcxIh2jZA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"my_keras_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgXdQc0qjZA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.load_model(\"my_keras_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNjERagXjZA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(X_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzpGP3j0jZA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(\"my_keras_weights.ckpt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyDrRvKpjZA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"my_keras_weights.ckpt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_3cpZEOjZBB",
        "colab_type": "text"
      },
      "source": [
        "# Using Callbacks "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHx1fq3LjZBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJN527j3jZBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2 = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"relu\", name=\"Layer_Dense\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG2_qOK0jZBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvR-BU4JjZBH",
        "colab_type": "text"
      },
      "source": [
        "The `ModelCheckpoint` callback saves checkpoints of your model at regular intervals during training, by default at the end of each epoch:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpoBWYvLjZBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model_2.h5\", save_best_only=True)\n",
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiCWtwpgjZBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.load_model(\"my_keras_model_2.h5\") # rollback to best model\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27RMCv7mjZBK",
        "colab_type": "text"
      },
      "source": [
        "The `EarlyStopping` callback will keep track of the best weights and restore them for you at the end of training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NKmWWE0VjZBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
        "history = model.fit(X_train, y_train, epochs=50,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gle6aFS0jZBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "save_fig(\"keras_learning_curves_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt2CK2fbjZBO",
        "colab_type": "text"
      },
      "source": [
        "# Using TensorBoard for Visualization \n",
        "* **TensorBoard** is a great interactive visualization tool that you can use to view the learning curves during training, compare learning curves between multiple runs, visualize the computation graph, analyze training statistics, view images generated by your model, visualize complex multidimensional data projected down to 3D and automatically clustered for you, and more! This tool is installed automatically when you install TensorFlow, so you already have it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQGQonFGjZBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_logdir = os.path.join(os.curdir, \"my_logs\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im48MrtPjZBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_run_logdir():\n",
        "    import time\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "run_logdir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESKUAt3jjZBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDtcvvxojZBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_3 = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"relu\", name=\"Layer_Dense\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model_3.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pecw3UXWjZBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb, tensorboard_cb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp5oPfixjZBW",
        "colab_type": "text"
      },
      "source": [
        "To start the TensorBoard server, one option is to open a terminal, if needed activate the virtualenv where you installed TensorBoard, go to this notebook's directory, then type:\n",
        "\n",
        "```bash\n",
        "$ tensorboard --logdir=./my_logs --port=6006\n",
        "```\n",
        "\n",
        "You can then open your web browser to [localhost:6006](http://localhost:6006) and use TensorBoard. Once you are done, press Ctrl-C in the terminal window, this will shutdown the TensorBoard server.\n",
        "\n",
        "Alternatively, you can load TensorBoard's Jupyter extension and run it like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9GT3XRCjZBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=./my_logs --port=6006"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_OI-0XdjZBX",
        "colab_type": "text"
      },
      "source": [
        "# Reference\n",
        "\n",
        "* [Machine Learning](https://medium.com/mmp-li/%E0%B9%80%E0%B8%A3%E0%B8%B4%E0%B9%88%E0%B8%A1%E0%B9%80%E0%B8%A3%E0%B8%B5%E0%B8%A2%E0%B8%99-machine-learning-0-100-introduction-1c58e516bfcd).\n",
        "* [Artificial Neural Network](https://medium.com/mmp-li/deep-learning-%E0%B9%81%E0%B8%9A%E0%B8%9A%E0%B8%89%E0%B8%9A%E0%B8%B1%E0%B8%9A%E0%B8%84%E0%B8%99%E0%B8%AA%E0%B8%B2%E0%B8%A1%E0%B8%B1%E0%B8%8D%E0%B8%8A%E0%B8%99-ep-1-neural-network-history-f7789236a9a3).\n",
        "\n",
        "* [Machine Learning Notebooks: Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow](https://github.com/ageron/handson-ml2).\n",
        "\n",
        "* [Artificial Intelligence with Machine Learning, AI สร้างได้ด้วยแมชชีนเลิร์นนิ่ง](https://www.se-ed.com/product/Artificial-Intelligence-with-Machine-Learning-AI-%E0%B8%AA%E0%B8%A3%E0%B9%89%E0%B8%B2%E0%B8%87%E0%B9%84%E0%B8%94%E0%B9%89%E0%B8%94%E0%B9%89%E0%B8%A7%E0%B8%A2%E0%B9%81%E0%B8%A1%E0%B8%8A%E0%B8%8A%E0%B8%B5%E0%B8%99%E0%B9%80%E0%B8%A5%E0%B8%B4%E0%B8%A3%E0%B9%8C%E0%B8%99%E0%B8%99%E0%B8%B4%E0%B9%88%E0%B8%87.aspx?no=9786164870710).\n",
        "\n",
        "* [Python Image Processing Cookbook](https://github.com/PacktPublishing/Python-Image-Processing-Cookbook)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJTWNrrTjZBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}